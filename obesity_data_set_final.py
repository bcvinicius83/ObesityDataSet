# -*- coding: utf-8 -*-
"""Obesity Data Set Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wboxzURV0zUqE-K7GJMuSIjMW0y0gCze
"""

# Importação de bibliotecas pandas para manipulação e análise de dados, numpy
# para operações numéricas, matplotlib.pyplot e seaborn para visualização de dados.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Importando base de dados


df = pd.read_csv('/content/ObesityDataSet.csv')
display(df.head())

# Definição do alvo e verificação do formato do dataset

target = df['death_risk']
features = df.drop('death_risk', axis=1)

print("Target variable shape:", target.shape)
print("Features shape:", features.shape)

# Concatenar dados + alvo
data = np.c_[features, target]
display(data)

# Criação do data frame
dataset = pd.DataFrame(data=data, columns=df.columns)
display(dataset.head())

# Verificar informações do dataset
dataset.info()

# Exibir o dataset completo
display(dataset)

# Realizar ajuste de dados por meio de one-hot encoding nas colunas selecionadas
#do dataframe
columns_to_encode_subset = ['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']

# Aplica o One-Hot Encoding a essas colunas no DataFrame original df, criando
# colunas binárias para cada categoria (exceto uma, devido ao drop_first=True
# para evitar multicolinearidade).
df_subset_encoded = pd.get_dummies(df, columns=columns_to_encode_subset, drop_first=True)

# Converter colunas booleanas para inteiros
for col in df_subset_encoded.columns:
    if df_subset_encoded[col].dtype == 'bool':
        df_subset_encoded[col] = df_subset_encoded[col].astype(int)

display(df_subset_encoded.head())

# Exibir o DataFrame codificado
print(df_subset_encoded)

#Mantendo a coluna Height com uma casa decimal
column_to_round_1_subset = 'Height'

# Mantendo FCVC, NCP e FAF com inteiros
columns_to_convert_int_subset = ['FCVC', 'NCP', 'FAF']

for col in columns_to_convert_int_subset:
    df_subset_encoded[col] = df_subset_encoded[col].round(0).astype(int)

df_subset_encoded[column_to_round_1_subset] = df_subset_encoded[column_to_round_1_subset].round(1)


display(df_subset_encoded.head())

# Exibir o DataFrame após arredondamentos e conversões
print(df_subset_encoded)

# Mandendo CH2O e TUE com 1 casa decimal
columns_to_round_1_more = ['CH2O', 'TUE']

for col in columns_to_round_1_more:
    df_subset_encoded[col] = df_subset_encoded[col].round(1)

display(df_subset_encoded.head())

# Efetuar o one-hot encoding nas colunas categóricas restantes
#One hot encoding nas categorias
columns_to_encode_remaining = ['CAEC', 'CALC', 'MTRANS', 'obesity_level']

# Identify columns already encoded
encoded_columns_from_previous_step = ['Gender_Male', 'family_history_with_overweight_yes', 'FAVC_yes', 'SMOKE_yes', 'SCC_yes']

# Filter out columns that have already been encoded
columns_to_encode_remaining_filtered = [col for col in columns_to_encode_remaining if col in df_subset_encoded.columns]


df_subset_encoded = pd.get_dummies(df_subset_encoded, columns=columns_to_encode_remaining_filtered, drop_first=True)

# Converter boleanos para inteiros
for col in df_subset_encoded.columns:
    if df_subset_encoded[col].dtype == 'bool':
        df_subset_encoded[col] = df_subset_encoded[col].astype(int)

# Converter 'Age' para inteiros e arredondar 'Weight' para 2 casas decimais
df_subset_encoded['Age'] = df_subset_encoded['Age'].astype(int)
df_subset_encoded['Weight'] = df_subset_encoded['Weight'].round(2)

display(df_subset_encoded.head())

# Plotar histograma da variável alv
# Atribui o DataFrame à variável dataset
# Define os rótulos dos eixos x e y e o título do gráfico.
dataset=df_subset_encoded
import matplotlib.pyplot as plt

plt.hist(dataset['death_risk'])
plt.xlabel('Death Risk')
plt.ylabel('Frequency')
plt.title('Distribution of Death Risk')
plt.show()

dataset['death_risk'] = dataset['death_risk'].astype(float)
display(dataset.info())

# Divisão do dataframe em treino e teste
from sklearn.model_selection import train_test_split

train_data, test_data = train_test_split(dataset, test_size=0.25, random_state=0)

train_data

test_data

# Preparar dados para modelagem e inicializar dicionário de resultados
# mporta StandardScaler para padronização de dados numéricos.
# Define as características (X) removendo a coluna 'death_risk' e a variável
# alvo (y) como a coluna 'death_risk'
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd

X = dataset.drop(['death_risk'], axis=1)
y = dataset['death_risk']



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

# Converter colunas booleanas em colunas inteiras antes e ajuste do scaler
for col in X_train.columns:
    if X_train[col].dtype == 'bool':
        X_train[col] = X_train[col].astype(int)
for col in X_test.columns:
    if X_test[col].dtype == 'bool':
        X_test[col] = X_test[col].astype(int)

scaler = StandardScaler()
# Transforma as colunas numéricas nos conjuntos de treino e teste usando
# o scaler ajustado.
numerical_cols = X_train.select_dtypes(include=np.number).columns
scaler.fit(X_train[numerical_cols])

X_train[numerical_cols] = scaler.transform(X_train[numerical_cols])
X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])

# Criando a estrutura do tipo dicionário
resultados = {
    "Algoritmo" :[],
    "Parametrização" :[],
    "Acuracia" :[],
    "Recall" :[] ,
    "Roc_auc" :[]
}

# Transforma as colunas numéricas nos conjuntos de treino e teste usando o
# scaler ajustado.
# Importa as métricas de avaliação accuracy_score, recall_score e roc_auc_score.
from sklearn.metrics import accuracy_score, recall_score, roc_auc_score

# Define a função avaliar_modelos que recebe o tipo de algoritmo, um dicionário
# de parametrizações, os dados de treino e teste, e o dicionário de resultados.
# Dentro da função, itera sobre as parametrizações, treina o classificador, faz
# previsões e calcula as métricas de acurácia, recall e ROC AUC, armazenando os
# resultados no dicionário resultados.
def avaliar_modelos(tipo, parametrizacoes, X_treino, y_treino, X_teste, y_teste, resultados):
    for parametrizacao in parametrizacoes:
        print("Avaliando", tipo, "com parametrização:", parametrizacao)
        classificador = parametrizacoes[parametrizacao]
        classificador.fit(X_treino, y_treino)
        y_pred = classificador.predict(X_teste)
        y_score = classificador.predict_proba(X_teste)[:, 1]
        # Adicionando aos resultados:
        resultados["Algoritmo"].append(tipo)
        resultados["Parametrização"].append(parametrizacao)
        resultados["Acuracia"].append(accuracy_score(y_test, y_pred))
        resultados["Recall"].append(recall_score(y_test, y_pred))
        resultados["Roc_auc"].append(roc_auc_score(y_test, y_score))

# Avaliar modelos SVM
from sklearn.svm import SVC
# definindo as diferentes configurações para o método SVM
# Define um dicionário modelos_svm com diferentes configurações (kernels e
# graus) para o modelo SVM
# Chama a função avaliar_modelos para treinar e avaliar os modelos SVM com as
# parametrizações definidas.
modelos_svm = {
    "Kernel rbf, gamma auto": SVC(kernel = 'rbf', gamma='auto', probability=True),
    "Kernel linear": SVC(kernel = 'linear', probability=True),
    "Kernel sigmoide": SVC(kernel = 'sigmoid', probability=True),
    "Kernel polinomial grau 2": SVC(kernel = 'poly', degree=2, probability=True),
    "Kernel polinomial grau 3": SVC(kernel = 'poly', degree=3, probability=True)
}

avaliar_modelos("SVM", modelos_svm, X_train, y_train, X_test, y_test, resultados)

from sklearn.svm import SVC
# definindo as diferentes configurações para o método SVM
modelos_svm = {
    "Kernel rbf, gamma auto": SVC(kernel = 'rbf', gamma='auto', probability=True),
    "Kernel linear": SVC(kernel = 'linear', probability=True),
    "Kernel sigmoide": SVC(kernel = 'sigmoid', probability=True),
    "Kernel polinomial grau 2": SVC(kernel = 'poly', degree=2, probability=True),
    "Kernel polinomial grau 3": SVC(kernel = 'poly', degree=3, probability=True)
}

avaliar_modelos("SVM", modelos_svm, X_train, y_train, X_test, y_test, resultados)

# Avaliar modelos Gaussian Naive Bayes
# Importa a classe GaussianNB do sklearn.naive_bayes.
# Define um dicionário modelos_gaussian com diferentes valores para o parâmetro var_smoothing.
# Chama a função avaliar_modelos para treinar e avaliar os modelos Gaussian Naive Bayes.
from sklearn.naive_bayes import GaussianNB
# definindo as diferentes configurações para o método NB
modelos_gaussian = {
    "Var smoothing 1e-9": GaussianNB(var_smoothing=1e-9),
    "Var smoothing 1e-8": GaussianNB(var_smoothing=1e-8),
    "Var smoothing 1e-7": GaussianNB(var_smoothing=1e-7),
    "Var smoothing 1e-6": GaussianNB(var_smoothing=1e-6),
    "Var smoothing 1e-5": GaussianNB(var_smoothing=1e-5)
}

avaliar_modelos("GaussianNB", modelos_gaussian, X_train, y_train, X_test, y_test, resultados)

# Avaliar modelos KNN
# Importa a classe KNeighborsClassifier do sklearn.neighbors.
# Define um dicionário modelos_knn com diferentes valores para o parâmetro n_neighbors.
# Chama a função avaliar_modelos para treinar e avaliar os modelos KNN.
from sklearn.neighbors import KNeighborsClassifier
# definindo as diferentes configurações para o método KNN
modelos_knn = {
    "N=3": KNeighborsClassifier(n_neighbors=3),
    "N=5": KNeighborsClassifier(n_neighbors=5),
    "N=7": KNeighborsClassifier(n_neighbors=7),
    "N=9": KNeighborsClassifier(n_neighbors=9),
    "N=11": KNeighborsClassifier(n_neighbors=11),
}

avaliar_modelos("KNN", modelos_knn, X_train, y_train, X_test, y_test, resultados)

# Exibir resultados em um DataFrame
# Cria um DataFrame do pandas (resultados_df) a partir do dicionário resultados
# que contém os resultados da avaliação de todos os modelos e parametrizações.
# display(resultados_df) mostra o DataFrame resultante.
resultados_df = pd.DataFrame.from_dict(resultados)
display(resultados_df)

# Encontrar os melhores ROC AUC por algoritmo
# Agrupa o DataFrame resultados_df pelo 'Algoritmo' e encontra o valor máximo de
# 'Roc_auc' para cada algoritmo.
# Armazena os melhores ROC AUCs em um novo DataFrame chamado best_roc_aucs.
# Exibe o DataFrame best_roc_aucs.
best_roc_aucs = resultados_df.groupby(["Algoritmo"])["Roc_auc"].agg([ ("Roc_auc", max) ])
best_roc_aucs

# Identificar as melhores parametrizações
# Cria um dicionário vazio chamado melhores_parametrizacoes.
# Itera sobre as linhas do DataFrame best_roc_aucs.
# Para cada algoritmo, encontra a parametrização que corresponde ao melhor valor
# de ROC AUC e a armazena no dicionário melhores_parametrizacoes.
# Imprime a melhor parametrização encontrada para cada algoritmo.
# Atribui as instâncias dos melhores modelos (com suas respectivas melhores
# parametrizações) às variáveis melhor_gaussiannb, melhor_KNN e melhor_svm.
melhores_parametrizacoes = {}
for linha in best_roc_aucs.itertuples():
    tipo_algo = linha[0]
    melhor_valor = linha[1]
    # Colocamos iloc[0] no final para pegar a primeira ocorrencia, pois podemos
    # ter mais de uma mesma parametrização com mesmo valor roc_aoc:
    melhores_parametrizacoes[tipo_algo] = resultados_df.query(
        "(Algoritmo==@tipo_algo) & (Roc_auc==@melhor_valor)").iloc[0]["Parametrização"]

    print("Melhor parametrização do", tipo_algo, "=", melhores_parametrizacoes[tipo_algo])

melhor_gaussiannb = modelos_gaussian[melhores_parametrizacoes["GaussianNB"]]
melhor_KNN = modelos_knn[melhores_parametrizacoes["KNN"]]
melhor_svm = modelos_svm[melhores_parametrizacoes["SVM"]]

# Plotar Curva ROC
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

plt.figure(figsize=(10,10))
lw = 2

y_score = melhor_gaussiannb.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=1)
roc_auc = best_roc_aucs.loc["GaussianNB"]
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='Gaussian (area = %0.4f)' % roc_auc)

y_score = melhor_KNN.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=1)
roc_auc = best_roc_aucs.loc["KNN"]
plt.plot(fpr, tpr, color='darkgreen', lw=lw, label='KNN (area = %0.4f)' % roc_auc)

y_score = melhor_svm.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=1)
roc_auc = best_roc_aucs.loc["SVM"]
plt.plot(fpr, tpr, color='darkblue', lw=lw, label='SVM (area = %0.4f)' % roc_auc)

plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', label='Aleatório')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa Falsos Positivos')
plt.ylabel('Taxa Verdadeiros Positivos')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()